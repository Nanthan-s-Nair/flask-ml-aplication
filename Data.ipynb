{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code with correct man prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/Users/nanthansnair/Downloads/jupiter/data1.csv')\n",
    "df['Actual flow volume air/gas'] = df['Actual flow volume air/gas'].str.replace('.', '').str.replace(',', '.').str.replace(' m3/h', '').astype(float)\n",
    "df['Pressure, static'] = df['Pressure, static'].str.replace('.', '').str.replace(',', '.').str.replace(' Pa', '').astype(float)\n",
    "df['Rated power'] = df['Rated power'].str.replace('.', '').str.replace(',', '.').str.replace(' kW', '').astype(float)\n",
    "df.drop(columns=['Unnamed: 5'], inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Check if the dataframe is not empty\n",
    "if not df.empty:\n",
    "    X = df[['Actual flow volume air/gas', 'Pressure, static']]\n",
    "    y = df['Rated power']\n",
    "\n",
    "    print(\"Shape of X:\", X.shape)\n",
    "    print(\"Shape of y:\", y.shape)\n",
    "\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    print(\"First 5 rows of X_scaled:\", X_scaled[:5])\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_test shape:\", X_test.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "    # Create the neural network model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=2, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=200, batch_size=5, verbose=1)\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss = model.evaluate(X_test, y_test)\n",
    "    print(f'Test Loss: {loss}')\n",
    "\n",
    "    # Function to recommend the correct fan\n",
    "    def recommend_fan(flow, pressure):\n",
    "        input_scaled = scaler.transform(np.array([[flow, pressure]]))\n",
    "        predicted_power = model.predict(input_scaled)[0][0]\n",
    "        df['Power Difference'] = abs(df['Rated power'] - predicted_power)\n",
    "        sorted_fans = df.sort_values(by='Power Difference', ascending=True)\n",
    "        best_fan = sorted_fans.iloc[0]\n",
    "        return best_fan[['Material description', 'Manufacturer', 'Rated power', 'Actual flow volume air/gas', 'Pressure, static', 'Power Difference']]\n",
    "\n",
    "    # Recommend the best fan for given flow and pressure\n",
    "    best_fan = recommend_fan(120000, 1450)\n",
    "    print(best_fan)\n",
    "\n",
    "else:\n",
    "    print(\"Some error occurred while processing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# load the data set\n",
    "df = pd.read_csv('/Users/nanthansnair/Downloads/jupiter/data1.csv')\n",
    "df['Actual flow volume air/gas'] = df['Actual flow volume air/gas'].str.replace(',', '').str.replace(' m3/h', '').astype(float)\n",
    "df['Pressure, static'] = df['Pressure, static'].str.replace(',', '').str.replace(' Pa', '').astype(float)\n",
    "df['Rated power'] = df['Rated power'].str.replace(' kW', '').astype(float)\n",
    "df.drop(columns=['Unnamed: 5'], inplace=True)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# to check if the columns are not empty\n",
    "if not df.empty:\n",
    "    X = df[['Actual flow volume air/gas', 'Pressure, static']]\n",
    "    y = df['Rated power']\n",
    "\n",
    "    print(\"Shape of X:\", X.shape)\n",
    "    print(\"Shape of y:\", y.shape)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    print(\"First 5 rows of X_scaled:\", X_scaled[:5])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_test shape:\", X_test.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "    # creating of neural network with 3 hidden layers\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=2, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    # model training with 200 epoches\n",
    "    model.fit(X_train, y_train, epochs=200, batch_size=5, verbose=1)\n",
    "\n",
    "    # working of the model and training\n",
    "    loss = model.evaluate(X_test, y_test)\n",
    "    print(f'Test Loss: {loss}')\n",
    "\n",
    "    # reccomend the correct fan\n",
    "    def recommend_fan(flow, pressure):\n",
    "        input_scaled = scaler.transform(np.array([[flow, pressure]]))\n",
    "        predicted_power = model.predict(input_scaled)[0][0]\n",
    "        df['Power Difference'] = abs(df['Rated power'] - predicted_power)\n",
    "        sorted_fans = df.sort_values(by='Power Difference', ascending=True)\n",
    "        best_fan = sorted_fans.iloc[0]\n",
    "        return best_fan\n",
    "\n",
    "\n",
    "    best_fan = recommend_fan(120000, 1450)\n",
    "    print(best_fan)\n",
    "    \n",
    "else:\n",
    "    print(\"some error occurred while processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'/Users/nanthansnair/Downloads/jupiter/data1.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code without man details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# load the data set\n",
    "df = pd.read_csv('/Users/nanthansnair/Downloads/jupiter/data1.csv')\n",
    "df['Actual flow volume air/gas'] = df['Actual flow volume air/gas'].str.replace(',', '').str.replace(' m3/h', '').astype(float)\n",
    "df['Pressure, static'] = df['Pressure, static'].str.replace(',', '').str.replace(' Pa', '').astype(float)\n",
    "df['Rated power'] = df['Rated power'].str.replace(' kW', '').astype(float)\n",
    "df.drop(columns=['Unnamed: 5'], inplace=True)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# to check if the columns are not empty\n",
    "if not df.empty:\n",
    "    X = df[['Actual flow volume air/gas', 'Pressure, static']]\n",
    "    y = df['Rated power']\n",
    "\n",
    "    print(\"Shape of X:\", X.shape)\n",
    "    print(\"Shape of y:\", y.shape)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    print(\"First 5 rows of X_scaled:\", X_scaled[:5])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_test shape:\", X_test.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "    # creating of neural network with 3 hidden layers\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=2, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    # model training with 200 epoches\n",
    "    model.fit(X_train, y_train, epochs=200, batch_size=5, verbose=1)\n",
    "\n",
    "    # working of the model and training\n",
    "    loss = model.evaluate(X_test, y_test)\n",
    "    print(f'Test Loss: {loss}')\n",
    "\n",
    "    # reccomend the correct fan\n",
    "    def recommend_fan(flow, pressure):\n",
    "        input_scaled = scaler.transform(np.array([[flow, pressure]]))\n",
    "        predicted_power = model.predict(input_scaled)[0][0]\n",
    "        df['Power Difference'] = abs(df['Rated power'] - predicted_power)\n",
    "        sorted_fans = df.sort_values(by='Power Difference', ascending=True)\n",
    "        best_fan = sorted_fans.iloc[0]\n",
    "        return best_fan\n",
    "\n",
    "\n",
    "    best_fan = recommend_fan(120000, 1450)\n",
    "    print(best_fan)\n",
    "    \n",
    "else:\n",
    "    print(\"some error occurred while processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/Users/nanthansnair/Downloads/jupiter/data1.csv')\n",
    "\n",
    "# Debugging print statement\n",
    "print(\"Original DataFrame:\\n\", df)\n",
    "\n",
    "# Data preprocessing\n",
    "df['Actual flow volume air/gas'] = df['Actual flow volume air/gas'].str.replace('.', '').str.replace(',', '.').str.replace(' m3/h', '').astype(float)\n",
    "df['Pressure, static'] = df['Pressure, static'].str.replace('.', '').str.replace(',', '.').str.replace(' Pa', '').astype(float)\n",
    "df['Rated power'] = df['Rated power'].str.replace('.', '').str.replace(',', '.').str.replace(' kW', '').astype(float)\n",
    "\n",
    "# Drop columns and NaN values\n",
    "if 'Unnamed: 5' in df.columns:\n",
    "    df.drop(columns=['Unnamed: 5'], inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Debugging print statement\n",
    "print(\"Processed DataFrame:\\n\", df)\n",
    "\n",
    "# Check if the dataframe is not empty\n",
    "if not df.empty:\n",
    "    X = df[['Actual flow volume air/gas', 'Pressure, static']]\n",
    "    y = df['Rated power']\n",
    "\n",
    "    print(\"Shape of X:\", X.shape)\n",
    "    print(\"Shape of y:\", y.shape)\n",
    "\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    print(\"First 5 rows of X_scaled:\", X_scaled[:5])\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_test shape:\", X_test.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "    # Create the neural network model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=2, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=200, batch_size=5, verbose=1)\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss = model.evaluate(X_test, y_test)\n",
    "    print(f'Test Loss: {loss}')\n",
    "\n",
    "\n",
    "    def recommend_fan(flow, pressure):\n",
    "        input_scaled = scaler.transform(np.array([[flow, pressure]]))\n",
    "        predicted_power = model.predict(input_scaled)[0][0]\n",
    "        df['Power Difference'] = abs(df['Rated power'] - predicted_power)\n",
    "        sorted_fans = df.sort_values(by='Power Difference', ascending=True)\n",
    "        best_fan = sorted_fans.iloc[0]\n",
    "        return best_fan[['Material description', 'Manufacturer', 'Rated power', 'Actual flow volume air/gas', 'Pressure, static', 'Power Difference']]\n",
    "\n",
    "\n",
    "    best_fan = recommend_fan(120000, 1450)\n",
    "    print(best_fan)\n",
    "\n",
    "else:\n",
    "    print(\"Some error occurred while processing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# load the data set\n",
    "df = pd.read_csv('/Users/nanthansnair/Downloads/jupiter/data1.csv')\n",
    "df['Actual flow volume air/gas'] = df['Actual flow volume air/gas'].str.replace(',', '').str.replace(' m3/h', '').astype(float)\n",
    "df['Pressure, static'] = df['Pressure, static'].str.replace(',', '').str.replace(' Pa', '').astype(float)\n",
    "df['Rated power'] = df['Rated power'].str.replace(' kW', '').astype(float)\n",
    "df.drop(columns=['Unnamed: 5'], inplace=True)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# to check if the columns are not empty\n",
    "if not df.empty:\n",
    "    X = df[['Actual flow volume air/gas', 'Pressure, static']]\n",
    "    y = df['Rated power']\n",
    "\n",
    "    print(\"Shape of X:\", X.shape)\n",
    "    print(\"Shape of y:\", y.shape)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    print(\"First 5 rows of X_scaled:\", X_scaled[:5])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_test shape:\", X_test.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "    # creating of neural network with 3 hidden layers\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=2, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    # model training with 200 epoches\n",
    "    model.fit(X_train, y_train, epochs=200, batch_size=5, verbose=1)\n",
    "\n",
    "    # working of the model and training\n",
    "    loss = model.evaluate(X_test, y_test)\n",
    "    print(f'Test Loss: {loss}')\n",
    "\n",
    "    # reccomend the correct fan\n",
    "    def recommend_fan(flow, pressure):\n",
    "        input_scaled = scaler.transform(np.array([[flow, pressure]]))\n",
    "        predicted_power = model.predict(input_scaled)[0][0]\n",
    "        df['Power Difference'] = abs(df['Rated power'] - predicted_power)\n",
    "        sorted_fans = df.sort_values(by='Power Difference', ascending=True)\n",
    "        best_fan = sorted_fans.iloc[0]\n",
    "        return best_fan[['Material description', 'Manufacturer', 'Rated power', 'Actual flow volume air/gas', 'Pressure, static', 'Power Difference']]\n",
    "\n",
    "\n",
    "    best_fan = recommend_fan(120000, 1450)\n",
    "    print(best_fan)\n",
    "    \n",
    "else:\n",
    "    print(\"some error occurred while processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# load the data set\n",
    "df = pd.read_csv('/Users/nanthansnair/Downloads/jupiter/data1.csv')\n",
    "df['Actual flow volume air/gas'] = df['Actual flow volume air/gas'].str.replace(',', '').str.replace(' m3/h', '').astype(float)\n",
    "df['Pressure, static'] = df['Pressure, static'].str.replace(',', '').str.replace(' Pa', '').astype(float)\n",
    "df['Rated power'] = df['Rated power'].str.replace(' kW', '').astype(float)\n",
    "df.drop(columns=['Unnamed: 5'], inplace=True)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# to check if the columns are not empty\n",
    "if not df.empty:\n",
    "    X = df[['Actual flow volume air/gas', 'Pressure, static']]\n",
    "    y = df['Rated power']\n",
    "\n",
    "    print(\"Shape of X:\", X.shape)\n",
    "    print(\"Shape of y:\", y.shape)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    print(\"First 5 rows of X_scaled:\", X_scaled[:5])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_test shape:\", X_test.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "    # creating of neural network with 3 hidden layers\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=2, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    # model training with 200 epoches\n",
    "    model.fit(X_train, y_train, epochs=200, batch_size=5, verbose=1)\n",
    "\n",
    "    # working of the model and training\n",
    "    loss = model.evaluate(X_test, y_test)\n",
    "    print(f'Test Loss: {loss}')\n",
    "\n",
    "    # reccomend the correct fan\n",
    "    def recommend_fan(flow, pressure):\n",
    "        input_scaled = scaler.transform(np.array([[flow, pressure]]))\n",
    "        predicted_power = model.predict(input_scaled)[0][0]\n",
    "        df['Power Difference'] = abs(df['Rated power'] - predicted_power)\n",
    "        sorted_fans = df.sort_values(by='Power Difference', ascending=True)\n",
    "        best_fan = sorted_fans.iloc[0]\n",
    "        return best_fan[['Material description', 'Manufacturer', 'Rated power', 'Actual flow volume air/gas', 'Pressure, static', 'Power Difference']]\n",
    "\n",
    "\n",
    "    best_fan = recommend_fan(3000,1000)\n",
    "    print(best_fan)\n",
    "    \n",
    "else:\n",
    "    print(\"some error occurred while processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# load the data set\n",
    "df = pd.read_csv('/Users/nanthansnair/Downloads/jupiter/data1.csv')\n",
    "df['Actual flow volume air/gas'] = df['Actual flow volume air/gas'].str.replace(',', '').str.replace(' m3/h', '').astype(float)\n",
    "df['Pressure, static'] = df['Pressure, static'].str.replace(',', '').str.replace(' Pa', '').astype(float)\n",
    "df['Rated power'] = df['Rated power'].str.replace(' kW', '').astype(float)\n",
    "df.drop(columns=['Unnamed: 5'], inplace=True)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# to check if the columns are not empty\n",
    "if not df.empty:\n",
    "    X = df[['Actual flow volume air/gas', 'Pressure, static']]\n",
    "    y = df['Rated power']\n",
    "\n",
    "    print(\"Shape of X:\", X.shape)\n",
    "    print(\"Shape of y:\", y.shape)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    print(\"First 5 rows of X_scaled:\", X_scaled[:5])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_test shape:\", X_test.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "    # creating of neural network with 3 hidden layers\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=2, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    # model training with 200 epoches\n",
    "    model.fit(X_train, y_train, epochs=200, batch_size=5, verbose=1)\n",
    "\n",
    "    # working of the model and training\n",
    "    loss = model.evaluate(X_test, y_test)\n",
    "    print(f'Test Loss: {loss}')\n",
    "\n",
    "    # reccomend the correct fan\n",
    "    def recommend_fan(flow, pressure):\n",
    "        input_scaled = scaler.transform(np.array([[flow, pressure]]))\n",
    "        predicted_power = model.predict(input_scaled)[0][0]\n",
    "        df['Power Difference'] = abs(df['Rated power'] - predicted_power)\n",
    "        sorted_fans = df.sort_values(by='Power Difference', ascending=True)\n",
    "        best_fan = sorted_fans.iloc[0]\n",
    "        return best_fan[['Material description', 'Manufacturer', 'Rated power', 'Actual flow volume air/gas', 'Pressure, static', 'Power Difference']]\n",
    "\n",
    "\n",
    "    best_fan = recommend_fan(9000,600)\n",
    "    print(best_fan)\n",
    "    \n",
    "else:\n",
    "    print(\"some error occurred while processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# load the data set\n",
    "df = pd.read_csv('/Users/nanthansnair/Downloads/jupiter/data1.csv')\n",
    "df['Actual flow volume air/gas'] = df['Actual flow volume air/gas'].str.replace(',', '').str.replace(' m3/h', '').astype(float)\n",
    "df['Pressure, static'] = df['Pressure, static'].str.replace(',', '').str.replace(' Pa', '').astype(float)\n",
    "df['Rated power'] = df['Rated power'].str.replace(' kW', '').astype(float)\n",
    "df.drop(columns=['Unnamed: 5'], inplace=True)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# to check if the columns are not empty\n",
    "if not df.empty:\n",
    "    X = df[['Actual flow volume air/gas', 'Pressure, static']]\n",
    "    y = df['Rated power']\n",
    "\n",
    "    print(\"Shape of X:\", X.shape)\n",
    "    print(\"Shape of y:\", y.shape)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    print(\"First 5 rows of X_scaled:\", X_scaled[:5])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_test shape:\", X_test.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "    # creating of neural network with 3 hidden layers\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=2, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    # model training with 200 epoches\n",
    "    model.fit(X_train, y_train, epochs=200, batch_size=5, verbose=1)\n",
    "\n",
    "    # working of the model and training\n",
    "    loss = model.evaluate(X_test, y_test)\n",
    "    print(f'Test Loss: {loss}')\n",
    "\n",
    "    # reccomend the correct fan\n",
    "    def recommend_fan(flow, pressure):\n",
    "        input_scaled = scaler.transform(np.array([[flow, pressure]]))\n",
    "        predicted_power = model.predict(input_scaled)[0][0]\n",
    "        df['Power Difference'] = abs(df['Rated power'] - predicted_power)\n",
    "        sorted_fans = df.sort_values(by='Power Difference', ascending=True)\n",
    "        best_fan = sorted_fans.iloc[0]\n",
    "        return best_fan[['Material description', 'Manufacturer', 'Rated power', 'Actual flow volume air/gas', 'Pressure, static', 'Power Difference']]\n",
    "\n",
    "\n",
    "    best_fan = recommend_fan(8205,900)\n",
    "    print(best_fan)\n",
    "    \n",
    "else:\n",
    "    print(\"some error occurred while processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# load the data set\n",
    "df = pd.read_csv('/Users/nanthansnair/Downloads/jupiter/data1.csv')\n",
    "df['Actual flow volume air/gas'] = df['Actual flow volume air/gas'].str.replace(',', '').str.replace(' m3/h', '').astype(float)\n",
    "df['Pressure, static'] = df['Pressure, static'].str.replace(',', '').str.replace(' Pa', '').astype(float)\n",
    "df['Rated power'] = df['Rated power'].str.replace(' kW', '').astype(float)\n",
    "df.drop(columns=['Unnamed: 5'], inplace=True)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# to check if the columns are not empty\n",
    "if not df.empty:\n",
    "    X = df[['Actual flow volume air/gas', 'Pressure, static']]\n",
    "    y = df['Rated power']\n",
    "\n",
    "    print(\"Shape of X:\", X.shape)\n",
    "    print(\"Shape of y:\", y.shape)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    print(\"First 5 rows of X_scaled:\", X_scaled[:5])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_test shape:\", X_test.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "    # creating of neural network with 3 hidden layers\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=2, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    # model training with 200 epoches\n",
    "    model.fit(X_train, y_train, epochs=200, batch_size=5, verbose=1)\n",
    "\n",
    "    # working of the model and training\n",
    "    loss = model.evaluate(X_test, y_test)\n",
    "    print(f'Test Loss: {loss}')\n",
    "\n",
    "    # reccomend the correct fan\n",
    "    def recommend_fan(flow, pressure):\n",
    "        input_scaled = scaler.transform(np.array([[flow, pressure]]))\n",
    "        predicted_power = model.predict(input_scaled)[0][0]\n",
    "        df['Power Difference'] = abs(df['Rated power'] - predicted_power)\n",
    "        sorted_fans = df.sort_values(by='Power Difference', ascending=True)\n",
    "        best_fan = sorted_fans.iloc[0]\n",
    "        return best_fan[['Material description', 'Manufacturer', 'Rated power', 'Actual flow volume air/gas', 'Pressure, static', 'Power Difference']]\n",
    "\n",
    "\n",
    "    best_fan = recommend_fan(27000,1330)\n",
    "    print(best_fan)\n",
    "    \n",
    "else:\n",
    "    print(\"some error occurred while processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (649, 2)\n",
      "Shape of y: (649,)\n",
      "First 5 rows of X_scaled: [[ 0.44861033  0.3248861 ]\n",
      " [-0.20586754  0.3248861 ]\n",
      " [-0.65348366  1.24456892]\n",
      " [ 0.07682015 -0.50282843]\n",
      " [ 0.28293393 -0.50282843]]\n",
      "X_train shape: (519, 2)\n",
      "X_test shape: (130, 2)\n",
      "y_train shape: (519,)\n",
      "y_test shape: (130,)\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - loss: 1820.4707\n",
      "Epoch 2/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267us/step - loss: 779.5576\n",
      "Epoch 3/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269us/step - loss: 132.3440\n",
      "Epoch 4/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step - loss: 99.2462\n",
      "Epoch 5/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266us/step - loss: 75.9064\n",
      "Epoch 6/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263us/step - loss: 89.0111\n",
      "Epoch 7/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272us/step - loss: 59.7684\n",
      "Epoch 8/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step - loss: 77.4925\n",
      "Epoch 9/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - loss: 45.5104\n",
      "Epoch 10/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266us/step - loss: 29.2170\n",
      "Epoch 11/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268us/step - loss: 36.9181\n",
      "Epoch 12/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 41.7954\n",
      "Epoch 13/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265us/step - loss: 37.2980\n",
      "Epoch 14/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267us/step - loss: 36.3442\n",
      "Epoch 15/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277us/step - loss: 26.3516\n",
      "Epoch 16/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267us/step - loss: 27.2740\n",
      "Epoch 17/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 35.3829\n",
      "Epoch 18/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step - loss: 27.1685\n",
      "Epoch 19/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 29.5484\n",
      "Epoch 20/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 33.5518\n",
      "Epoch 21/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 33.9967\n",
      "Epoch 22/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 23.1181\n",
      "Epoch 23/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 27.4783\n",
      "Epoch 24/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 27.1466\n",
      "Epoch 25/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 25.1377\n",
      "Epoch 26/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 24.6500\n",
      "Epoch 27/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 23.0450\n",
      "Epoch 28/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 26.6376\n",
      "Epoch 29/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step - loss: 23.6177\n",
      "Epoch 30/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287us/step - loss: 21.6261\n",
      "Epoch 31/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 35.5726\n",
      "Epoch 32/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 24.1209\n",
      "Epoch 33/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 26.5102\n",
      "Epoch 34/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step - loss: 25.3011\n",
      "Epoch 35/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 20.8477\n",
      "Epoch 36/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266us/step - loss: 22.5826\n",
      "Epoch 37/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273us/step - loss: 17.2639\n",
      "Epoch 38/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268us/step - loss: 22.5377\n",
      "Epoch 39/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 18.4972\n",
      "Epoch 40/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 24.8262\n",
      "Epoch 41/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 23.8643\n",
      "Epoch 42/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 20.4524\n",
      "Epoch 43/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 26.5071\n",
      "Epoch 44/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 24.3306\n",
      "Epoch 45/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 28.2927\n",
      "Epoch 46/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 24.7000\n",
      "Epoch 47/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 24.7251\n",
      "Epoch 48/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 21.0221\n",
      "Epoch 49/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 21.2536\n",
      "Epoch 50/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 19.7009\n",
      "Epoch 51/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266us/step - loss: 27.7308\n",
      "Epoch 52/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271us/step - loss: 17.5784\n",
      "Epoch 53/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step - loss: 22.8255\n",
      "Epoch 54/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step - loss: 25.7767\n",
      "Epoch 55/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - loss: 20.6573\n",
      "Epoch 56/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step - loss: 21.2126\n",
      "Epoch 57/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 20.2373\n",
      "Epoch 58/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267us/step - loss: 18.2316\n",
      "Epoch 59/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 18.3237\n",
      "Epoch 60/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step - loss: 21.3084\n",
      "Epoch 61/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 23.1699\n",
      "Epoch 62/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step - loss: 14.3684\n",
      "Epoch 63/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268us/step - loss: 21.3189\n",
      "Epoch 64/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 19.8867\n",
      "Epoch 65/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 23.9255\n",
      "Epoch 66/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 18.2354\n",
      "Epoch 67/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 20.3392\n",
      "Epoch 68/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 21.3085\n",
      "Epoch 69/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 25.9818\n",
      "Epoch 70/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 19.3294\n",
      "Epoch 71/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 21.8688\n",
      "Epoch 72/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 19.3138\n",
      "Epoch 73/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 19.4150\n",
      "Epoch 74/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 30.2715\n",
      "Epoch 75/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 20.1924\n",
      "Epoch 76/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 22.2410\n",
      "Epoch 77/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 20.9709\n",
      "Epoch 78/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step - loss: 19.9279\n",
      "Epoch 79/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 15.7151\n",
      "Epoch 80/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266us/step - loss: 15.9212\n",
      "Epoch 81/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step - loss: 15.8465\n",
      "Epoch 82/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 15.0643\n",
      "Epoch 83/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 18.1826\n",
      "Epoch 84/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 18.4187\n",
      "Epoch 85/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step - loss: 27.2315\n",
      "Epoch 86/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 19.4530\n",
      "Epoch 87/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284us/step - loss: 18.9514\n",
      "Epoch 88/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 14.4711\n",
      "Epoch 89/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 19.1800\n",
      "Epoch 90/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 15.8141\n",
      "Epoch 91/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step - loss: 16.7864\n",
      "Epoch 92/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 17.3010\n",
      "Epoch 93/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step - loss: 17.6739\n",
      "Epoch 94/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 21.1326\n",
      "Epoch 95/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 16.0098\n",
      "Epoch 96/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 16.2329\n",
      "Epoch 97/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 14.7300\n",
      "Epoch 98/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 20.6124\n",
      "Epoch 99/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 16.9167\n",
      "Epoch 100/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 17.2911\n",
      "Epoch 101/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252us/step - loss: 20.2869\n",
      "Epoch 102/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - loss: 18.2697\n",
      "Epoch 103/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 20.5326\n",
      "Epoch 104/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 13.9884\n",
      "Epoch 105/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 21.4260\n",
      "Epoch 106/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 20.0253\n",
      "Epoch 107/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 18.0211\n",
      "Epoch 108/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 22.3039\n",
      "Epoch 109/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 17.1249\n",
      "Epoch 110/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step - loss: 15.9652\n",
      "Epoch 111/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step - loss: 17.1252\n",
      "Epoch 112/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step - loss: 16.8535\n",
      "Epoch 113/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 17.8785\n",
      "Epoch 114/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step - loss: 19.8285\n",
      "Epoch 115/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 16.2082\n",
      "Epoch 116/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263us/step - loss: 17.9904\n",
      "Epoch 117/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 18.6615\n",
      "Epoch 118/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 14.7130\n",
      "Epoch 119/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 28.9044\n",
      "Epoch 120/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285us/step - loss: 21.1583\n",
      "Epoch 121/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 22.3966\n",
      "Epoch 122/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - loss: 17.0622\n",
      "Epoch 123/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 14.1625\n",
      "Epoch 124/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step - loss: 17.5306\n",
      "Epoch 125/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 18.0923\n",
      "Epoch 126/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 26.4525\n",
      "Epoch 127/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 17.4910\n",
      "Epoch 128/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 20.7148\n",
      "Epoch 129/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 19.5604\n",
      "Epoch 130/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 17.6673\n",
      "Epoch 131/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 19.7868\n",
      "Epoch 132/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 15.6385\n",
      "Epoch 133/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 17.4820\n",
      "Epoch 134/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 13.5714\n",
      "Epoch 135/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 16.3367\n",
      "Epoch 136/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 13.4516\n",
      "Epoch 137/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 13.6312\n",
      "Epoch 138/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 16.6072\n",
      "Epoch 139/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 18.6561\n",
      "Epoch 140/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 17.8751\n",
      "Epoch 141/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 16.8856\n",
      "Epoch 142/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 13.0378\n",
      "Epoch 143/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 16.3239\n",
      "Epoch 144/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - loss: 20.5356\n",
      "Epoch 145/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276us/step - loss: 13.5673\n",
      "Epoch 146/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 18.4804\n",
      "Epoch 147/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 17.7748\n",
      "Epoch 148/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step - loss: 19.6331\n",
      "Epoch 149/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291us/step - loss: 18.5344\n",
      "Epoch 150/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 17.0074\n",
      "Epoch 151/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 16.2940\n",
      "Epoch 152/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 16.1906\n",
      "Epoch 153/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 14.1606\n",
      "Epoch 154/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263us/step - loss: 21.2204\n",
      "Epoch 155/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 16.7440\n",
      "Epoch 156/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 19.4305\n",
      "Epoch 157/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 18.9264\n",
      "Epoch 158/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 16.7678\n",
      "Epoch 159/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 19.3892\n",
      "Epoch 160/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 16.6954\n",
      "Epoch 161/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - loss: 15.3427\n",
      "Epoch 162/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 20.4132\n",
      "Epoch 163/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 15.2328\n",
      "Epoch 164/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 14.6146\n",
      "Epoch 165/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step - loss: 21.3738\n",
      "Epoch 166/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253us/step - loss: 17.6741\n",
      "Epoch 167/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 20.2866\n",
      "Epoch 168/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 16.3679\n",
      "Epoch 169/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step - loss: 13.2738\n",
      "Epoch 170/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 22.0311\n",
      "Epoch 171/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 20.1197\n",
      "Epoch 172/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 15.3490\n",
      "Epoch 173/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step - loss: 14.6200\n",
      "Epoch 174/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 15.3154\n",
      "Epoch 175/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 17.8048\n",
      "Epoch 176/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 14.8462\n",
      "Epoch 177/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step - loss: 16.0485\n",
      "Epoch 178/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 11.8716\n",
      "Epoch 179/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - loss: 15.7693\n",
      "Epoch 180/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273us/step - loss: 17.2273\n",
      "Epoch 181/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284us/step - loss: 18.9661\n",
      "Epoch 182/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step - loss: 17.4385\n",
      "Epoch 183/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252us/step - loss: 17.4494\n",
      "Epoch 184/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 14.1481\n",
      "Epoch 185/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 15.2464\n",
      "Epoch 186/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 18.0249\n",
      "Epoch 187/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 18.7683\n",
      "Epoch 188/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 20.0423\n",
      "Epoch 189/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 15.3987\n",
      "Epoch 190/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 19.8849\n",
      "Epoch 191/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 17.2420\n",
      "Epoch 192/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 13.9275\n",
      "Epoch 193/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 13.7394\n",
      "Epoch 194/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 15.5305\n",
      "Epoch 195/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251us/step - loss: 14.9643\n",
      "Epoch 196/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 15.7252\n",
      "Epoch 197/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - loss: 18.1924\n",
      "Epoch 198/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270us/step - loss: 16.4680\n",
      "Epoch 199/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267us/step - loss: 17.7186\n",
      "Epoch 200/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 18.6944\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 13.6717\n",
      "Test Loss: 11.517975807189941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Material description          Centrifugal plug fan\n",
      "Manufacturer                          HYGIENIC AIR\n",
      "Rated power                                   18.5\n",
      "Actual flow volume air/gas                 32000.0\n",
      "Pressure, static                            1100.0\n",
      "Power Difference                          0.830965\n",
      "Name: 139, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# load the data set\n",
    "df = pd.read_csv('/Users/nanthansnair/Downloads/jupiter/data1.csv')\n",
    "df['Actual flow volume air/gas'] = df['Actual flow volume air/gas'].str.replace(',', '').str.replace(' m3/h', '').astype(float)\n",
    "df['Pressure, static'] = df['Pressure, static'].str.replace(',', '').str.replace(' Pa', '').astype(float)\n",
    "df['Rated power'] = df['Rated power'].str.replace(' kW', '').astype(float)\n",
    "df.drop(columns=['Unnamed: 5'], inplace=True)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# to check if the columns are not empty\n",
    "if not df.empty:\n",
    "    X = df[['Actual flow volume air/gas', 'Pressure, static']]\n",
    "    y = df['Rated power']\n",
    "\n",
    "    print(\"Shape of X:\", X.shape)\n",
    "    print(\"Shape of y:\", y.shape)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    print(\"First 5 rows of X_scaled:\", X_scaled[:5])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_test shape:\", X_test.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "    # creating of neural network with 3 hidden layers\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=2, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    # model training with 200 epoches\n",
    "    model.fit(X_train, y_train, epochs=200, batch_size=5, verbose=1)\n",
    "\n",
    "    # working of the model and training\n",
    "    loss = model.evaluate(X_test, y_test)\n",
    "    print(f'Test Loss: {loss}')\n",
    "\n",
    "    # reccomend the correct fan\n",
    "    def recommend_fan(flow, pressure):\n",
    "        input_scaled = scaler.transform(np.array([[flow, pressure]]))\n",
    "        predicted_power = model.predict(input_scaled)[0][0]\n",
    "        df['Power Difference'] = abs(df['Rated power'] - predicted_power)\n",
    "        sorted_fans = df.sort_values(by='Power Difference', ascending=True)\n",
    "        best_fan = sorted_fans.iloc[0]\n",
    "        return best_fan\n",
    "\n",
    "\n",
    "    best_fan = recommend_fan(27000,1330)\n",
    "    print(best_fan)\n",
    "    \n",
    "else:\n",
    "    print(\"some error occurred while processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# scatter plot\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = sns.scatterplot(x='Actual flow volume air/gas', y='Pressure, static', hue='Rated power', data=df, palette='viridis')\n",
    "plt.title('Flow vs Pressure colored by Rated Power')\n",
    "plt.xlabel('Actual flow volume air/gas (m3/h)')\n",
    "plt.ylabel('Pressure, static (Pa)')\n",
    "\n",
    "# Add colorbar\n",
    "\n",
    "\n",
    "\n",
    "# heatmap\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# relationship plot\n",
    "sns.pairplot(numeric_df, diag_kind='kde', markers='+')\n",
    "plt.suptitle('Pairplot of Variables', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# 3D plot \n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "sc = ax.scatter(df['Actual flow volume air/gas'], df['Pressure, static'], df['Rated power'], c=df['Rated power'], cmap='viridis')\n",
    "plt.colorbar(sc, label='Rated Power (kW)')\n",
    "ax.set_xlabel('Actual flow volume air/gas (m3/h)')\n",
    "ax.set_ylabel('Pressure, static (Pa)')\n",
    "ax.set_zlabel('Rated Power (kW)')\n",
    "ax.set_title('3D Plot of Flow, Pressure, and Rated Power')\n",
    "plt.show()\n",
    "\n",
    "# line plot \n",
    "\n",
    "flow_values = np.linspace(df['Actual flow volume air/gas'].min(), df['Actual flow volume air/gas'].max(), 10)  \n",
    "pressure_values = np.linspace(df['Pressure, static'].min(), df['Pressure, static'].max(), 10)  \n",
    "\n",
    "predicted_powers = []\n",
    "for flow in flow_values:\n",
    "    for pressure in pressure_values:\n",
    "        input_df = pd.DataFrame([[flow, pressure]], columns=['Actual flow volume air/gas', 'Pressure, static'])\n",
    "        predicted_power = model.predict(scaler.transform(input_df))[0][0]\n",
    "        predicted_powers.append((flow, pressure, predicted_power))\n",
    "\n",
    "predicted_df = pd.DataFrame(predicted_powers, columns=['Flow', 'Pressure', 'Predicted Power'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=predicted_df, x='Flow', y='Predicted Power', hue='Pressure', palette='coolwarm')\n",
    "plt.title('Predicted Power vs Flow and Pressure')\n",
    "plt.xlabel('Actual flow volume air/gas (m3/h)')\n",
    "plt.ylabel('Predicted Power (kW)')\n",
    "plt.legend(title='Pressure (Pa)', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Flow (m3/h)=%{x}<br>Pressure (Pa)=%{y}<br>Rated Power (kW)=%{marker.color}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": [
           45,
           22,
           15,
           15,
           18.5,
           37,
           30,
           18.5,
           15,
           3.7,
           7.5,
           22,
           30,
           15,
           15,
           15,
           15,
           18.5,
           15,
           15,
           15,
           18.5,
           5.5,
           30,
           30,
           5.5,
           37,
           37,
           22,
           11,
           15,
           37,
           30,
           75,
           75,
           30,
           22,
           15,
           30,
           15,
           110,
           110,
           4,
           2.2,
           45,
           160,
           160,
           110,
           15,
           22,
           45,
           1.1,
           30,
           2.2,
           30,
           22,
           15,
           3.7,
           18.5,
           2.2,
           45,
           30,
           7.5,
           15,
           45,
           45,
           22,
           30,
           22,
           15,
           90,
           15,
           37,
           30,
           55,
           15,
           30,
           22,
           22,
           22,
           22,
           45,
           45,
           45,
           22,
           30,
           22,
           37,
           75,
           55,
           30,
           75,
           11,
           15,
           30,
           37,
           30,
           30,
           30,
           55,
           30,
           30,
           30,
           5.5,
           55,
           55,
           55,
           75,
           75,
           45,
           45,
           30,
           45,
           45,
           37,
           75,
           75,
           45,
           30,
           18.5,
           30,
           15,
           11,
           11,
           37,
           18.5,
           15,
           15,
           22,
           15,
           90,
           90,
           15,
           37,
           37,
           37,
           22,
           37,
           15,
           18.5,
           37,
           11,
           3.7,
           3.7,
           7.5,
           15,
           18.5,
           18.5,
           18.5,
           37,
           15,
           132,
           132,
           3.7,
           5.5,
           5.5,
           7.5,
           75,
           22,
           22,
           15,
           110,
           22,
           55,
           30,
           22,
           15,
           45,
           75,
           75,
           90,
           37,
           45,
           37,
           45,
           22,
           30,
           30,
           15,
           22,
           30,
           90,
           7.5,
           55,
           55,
           75,
           22,
           30,
           30,
           22,
           22,
           22,
           18.5,
           7.5,
           45,
           45,
           11,
           15,
           7.5,
           5.5,
           37,
           22,
           22,
           22,
           5.5,
           3.7,
           7.5,
           7.5,
           45,
           3.7,
           3.7,
           37,
           3.7,
           11,
           5.5,
           22,
           3.7,
           3.7,
           45,
           55,
           45,
           132,
           5.5,
           1.1,
           2.2,
           132,
           132,
           15,
           7.5,
           30,
           18.5,
           5.5,
           75,
           75,
           75,
           75,
           90,
           90,
           37,
           2.2,
           2.2,
           2.2,
           3.7,
           30,
           3.7,
           55,
           2.2,
           1.5,
           0.55,
           1.5,
           37,
           55,
           2.2,
           30,
           1.1,
           0.75,
           1.5,
           5.5,
           110,
           110,
           18.5,
           200,
           90,
           30,
           4,
           4,
           11,
           15,
           45,
           2.2,
           2.2,
           1.5,
           3.7,
           5.5,
           5.5,
           15,
           15,
           18.5,
           30,
           110,
           132,
           132,
           37,
           110,
           132,
           132,
           132,
           160,
           160,
           22,
           90,
           75,
           22,
           3.7,
           11,
           1.5,
           1.5,
           2.2,
           2.2,
           1.5,
           2.2,
           2.2,
           2.2,
           2.2,
           7.5,
           5.5,
           11,
           2.2,
           2.2,
           45,
           45,
           1.1,
           45,
           55,
           1.5,
           3.7,
           5.5,
           11,
           11,
           75,
           3.7,
           3.7,
           1.1,
           2.2,
           1.1,
           5.5,
           11,
           1.1,
           1.5,
           2.2,
           9.3,
           7.5,
           7.5,
           7.5,
           7.5,
           11,
           45,
           55,
           75,
           45,
           3.7,
           3.7,
           2.2,
           2.2,
           2.2,
           2.2,
           2.2,
           2.2,
           3.7,
           3.7,
           22,
           30,
           11,
           11,
           15,
           2.2,
           30,
           37,
           5.5,
           1.1,
           1.1,
           2.2,
           2.2,
           2.2,
           3.7,
           75,
           5.5,
           9.3,
           3.7,
           2.2,
           2.2,
           2.2,
           45,
           30,
           11,
           30,
           11,
           30,
           30,
           1.5,
           3.7,
           2.2,
           2.2,
           2.2,
           2.2,
           2.2,
           2.2,
           2.2,
           3.7,
           7.5,
           3.7,
           3.7,
           5.5,
           5.5,
           11,
           22,
           75,
           22,
           75,
           1.5,
           3.7,
           2.2,
           15,
           2.2,
           2.2,
           2.2,
           7.5,
           7.5,
           15,
           3.7,
           5.5,
           3.7,
           11,
           15,
           3.7,
           7.5,
           37,
           1.1,
           2.2,
           3.7,
           5.5,
           45,
           3.7,
           37,
           2.2,
           2.2,
           1.1,
           0.75,
           22,
           90,
           110,
           30,
           1.5,
           3.7,
           1.5,
           1.5,
           2.2,
           2.2,
           1.1,
           2.2,
           7.5,
           15,
           110,
           110,
           2.2,
           15,
           3.7,
           1.5,
           7.5,
           7.5,
           5.5,
           1.1,
           5.5,
           75,
           37,
           1.5,
           1.5,
           75,
           5.5,
           18.5,
           5.5,
           1.1,
           2.2,
           1.5,
           2.5,
           5.5,
           11,
           1.5,
           30,
           5.5,
           5.5,
           3.7,
           5.5,
           2.2,
           2.2,
           15,
           5.5,
           5.5,
           3.7,
           2.2,
           2.2,
           15,
           2.2,
           3.7,
           3.7,
           1.5,
           15,
           15,
           18.5,
           22,
           2.2,
           2.2,
           3.7,
           3.7,
           22,
           15,
           2.2,
           3.7,
           3.7,
           2.2,
           3.7,
           7.5,
           18.5,
           132,
           3.7,
           1.5,
           1.5,
           3.7,
           5.5,
           55,
           160,
           75,
           75,
           75,
           22,
           110,
           110,
           132,
           2.2,
           7.5,
           5.5,
           18.5,
           30,
           18.5,
           11,
           132,
           90,
           90,
           22,
           18.5,
           15,
           1.1,
           37,
           30,
           22,
           3.7,
           37,
           15,
           2.2,
           3.7,
           3.7,
           11,
           30,
           22,
           30,
           45,
           11,
           7.5,
           2.2,
           55,
           160,
           132,
           2.2,
           7.5,
           45,
           45,
           30,
           7.5,
           7.5,
           45,
           1.1,
           2.2,
           110,
           55,
           1.1,
           2.2,
           18.5,
           2.2,
           5.5,
           110,
           110,
           90,
           90,
           7.5,
           7.5,
           3.7,
           15,
           5.5,
           3.7,
           3.7,
           5.5,
           11,
           3.7,
           7.5,
           3.7,
           3.7,
           5.5,
           7.5,
           2.2,
           30,
           11,
           5.5,
           2.2,
           5.5,
           7.5,
           1.5,
           5.5,
           1.5,
           15,
           110,
           2.2,
           7.5,
           5.5,
           5.5,
           30,
           75,
           75,
           11,
           7.5,
           5.5,
           7.5,
           2.2,
           7.5,
           3.7,
           1.5,
           3.7,
           15,
           5.5,
           15,
           3.7,
           30,
           11,
           11,
           5.5,
           2.2,
           2.2,
           11,
           2.2,
           3.7,
           2.2,
           2.2,
           2.2,
           2.2,
           11,
           110,
           110,
           11,
           2.2,
           7.5,
           18.5,
           1.1,
           5.5,
           2.2,
           5.5,
           5.5,
           7.5,
           15,
           37,
           75
          ],
          "coloraxis": "coloraxis",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          60000,
          32000,
          12850,
          44094,
          52912,
          45000,
          48000,
          66140,
          30000,
          12000,
          24000,
          40000,
          60000,
          10500,
          12850,
          10500,
          39684,
          36000,
          39684,
          39684,
          39684,
          36000,
          15000,
          40000,
          40000,
          10000,
          60000,
          51400,
          30000,
          33070,
          30000,
          60000,
          45000,
          102900,
          102900,
          45000,
          36000,
          39684,
          45000,
          49605,
          118900,
          118900,
          10000,
          4000,
          60000,
          142000,
          142000,
          133800,
          44094,
          40000,
          60000,
          4000,
          36000,
          4428,
          50000,
          36000,
          37741,
          5900,
          36000,
          9000,
          60000,
          45000,
          25500,
          24000,
          60000,
          75000,
          82675,
          45000,
          45000,
          49605,
          127650,
          40500,
          60000,
          45000,
          75000,
          45000,
          45000,
          60000,
          60000,
          60000,
          60000,
          60000,
          60000,
          60000,
          45000,
          60000,
          64000,
          49000,
          60000,
          42250,
          60000,
          48750,
          22000,
          20000,
          45000,
          60000,
          66000,
          78500,
          56000,
          60000,
          45000,
          48000,
          48000,
          12000,
          72500,
          72500,
          90000,
          104000,
          104000,
          60000,
          60000,
          75000,
          75000,
          60000,
          45000,
          112000,
          120000,
          60000,
          60000,
          66000,
          45000,
          24000,
          28914,
          9700,
          45000,
          30478,
          31351,
          31254,
          30000,
          31351,
          105000,
          105000,
          16000,
          45000,
          45000,
          45000,
          30000,
          45000,
          24000,
          32000,
          60000,
          9700,
          9000,
          12000,
          24000,
          36800,
          36000,
          36000,
          36000,
          60000,
          36000,
          154000,
          154000,
          9000,
          12000,
          12000,
          24000,
          87000,
          36000,
          36000,
          24000,
          160000,
          45000,
          60000,
          60000,
          45000,
          20000,
          49000,
          42750,
          48750,
          63000,
          45000,
          60000,
          45000,
          60000,
          40000,
          48000,
          36000,
          42500,
          52912,
          39512,
          19688,
          15675,
          15125,
          15125,
          18150,
          65000,
          70000,
          70000,
          55000,
          48000,
          60000,
          50000,
          19000,
          110000,
          110000,
          34000,
          38000,
          26000,
          14000,
          95000,
          65000,
          65000,
          55000,
          16500,
          12000,
          13125,
          12540,
          12100,
          10000,
          10000,
          95000,
          10000,
          28000,
          15000,
          50000,
          12000,
          12000,
          54000,
          63000,
          48000,
          165000,
          15000,
          4000,
          6500,
          200000,
          200000,
          37000,
          24000,
          86200,
          24000,
          20000,
          116000,
          116000,
          130000,
          130000,
          145000,
          145000,
          95000,
          8661,
          6782,
          6782,
          1340,
          43000,
          14000,
          79000,
          8000,
          4000,
          1250,
          4000,
          56000,
          93000,
          6000,
          49000,
          2400,
          2359,
          2500,
          17100,
          229000,
          255300,
          60000,
          267000,
          125000,
          98100,
          8500,
          10800,
          24000,
          43100,
          58000,
          5757,
          6000,
          8000,
          14000,
          20000,
          20000,
          56500,
          60000,
          71300,
          90000,
          143500,
          165500,
          152000,
          12510,
          24160,
          165500,
          139000,
          139000,
          182000,
          182000,
          53000,
          125000,
          93000,
          60100,
          7500,
          26800,
          3000,
          4000,
          6000,
          4000,
          5300,
          6000,
          7500,
          8000,
          8000,
          18000,
          17300,
          30800,
          7929,
          8627,
          74000,
          74000,
          3000,
          53500,
          66000,
          4000,
          10000,
          14000,
          25000,
          29000,
          80500,
          12000,
          13000,
          3172,
          8112,
          3245,
          10000,
          30000,
          2300,
          4000,
          5100,
          15000,
          17700,
          17700,
          18000,
          20000,
          29700,
          59050,
          70700,
          93550,
          120000,
          12000,
          10800,
          6000,
          6000,
          8000,
          8000,
          8295,
          6000,
          12100,
          12000,
          33000,
          47500,
          39000,
          38500,
          51300,
          4428,
          50000,
          48000,
          15000,
          650,
          3500,
          8500,
          8436,
          8112,
          13000,
          121850,
          21500,
          40500,
          12000,
          6000,
          8000,
          8000,
          85050,
          40000,
          7000,
          40000,
          7000,
          40000,
          40000,
          5000,
          12000,
          8000,
          4000,
          4000,
          6000,
          6000,
          8000,
          8000,
          12000,
          15000,
          12000,
          15000,
          14000,
          14000,
          36000,
          73000,
          120000,
          36000,
          85000,
          3000,
          9600,
          6000,
          45000,
          6000,
          5000,
          3000,
          15400,
          28800,
          29800,
          12000,
          16000,
          12800,
          20200,
          23200,
          12700,
          17700,
          45000,
          3000,
          4000,
          10000,
          15000,
          92500,
          9000,
          52900,
          8295,
          9075,
          4000,
          2000,
          74000,
          130000,
          145000,
          50000,
          5500,
          12000,
          6000,
          6000,
          8000,
          8000,
          4000,
          7600,
          26800,
          50200,
          163200,
          163200,
          9075,
          5000,
          10000,
          4043,
          9000,
          22000,
          15000,
          2000,
          15000,
          27000,
          13000,
          6000,
          6000,
          16800,
          21600,
          25200,
          21600,
          3000,
          9000,
          6000,
          6000,
          21000,
          18000,
          5000,
          75000,
          12000,
          12000,
          6000,
          12000,
          3000,
          5000,
          45000,
          12000,
          12000,
          6000,
          3000,
          5000,
          45000,
          5000,
          8000,
          12500,
          4000,
          36000,
          36000,
          22500,
          27000,
          4500,
          4500,
          8436,
          8112,
          41250,
          28000,
          6000,
          8205,
          9077,
          8000,
          12000,
          18000,
          54000,
          193000,
          12000,
          6000,
          6000,
          10000,
          12000,
          64750,
          153500,
          90000,
          85000,
          85000,
          30000,
          129000,
          133000,
          174000,
          6000,
          18000,
          12000,
          43500,
          60000,
          48000,
          30000,
          131500,
          130000,
          119000,
          36000,
          36000,
          21000,
          1940,
          45000,
          48000,
          54500,
          7930,
          45000,
          24000,
          4319,
          7747,
          7747,
          26500,
          48000,
          53000,
          48000,
          60000,
          18000,
          19500,
          3879,
          64750,
          153500,
          131500,
          4600,
          21600,
          52000,
          54000,
          36000,
          23000,
          18000,
          60000,
          2850,
          7000,
          145000,
          69000,
          2700,
          6000,
          63000,
          4429,
          6000,
          162500,
          162500,
          121200,
          126700,
          23600,
          24600,
          10000,
          11000,
          12000,
          12000,
          12000,
          12000,
          20000,
          10000,
          16000,
          10000,
          10800,
          12000,
          16200,
          5400,
          58000,
          7193,
          8094,
          6197,
          7691,
          16000,
          4373,
          12000,
          2500,
          35000,
          130500,
          7000,
          26000,
          16000,
          16000,
          65000,
          140000,
          140000,
          8000,
          24000,
          13000,
          12833,
          7332,
          12393,
          7746,
          4500,
          7500,
          31000,
          13500,
          34000,
          8600,
          73000,
          8000,
          26000,
          14000,
          6000,
          7000,
          15000,
          5200,
          10000,
          8000,
          3400,
          6000,
          7500,
          31200,
          126000,
          126000,
          31200,
          7500,
          20500,
          27000,
          2000,
          9000,
          4043,
          15000,
          15000,
          22000,
          34000,
          13000,
          27000
         ],
         "xaxis": "x",
         "y": [
          1500,
          1500,
          2500,
          600,
          600,
          1500,
          1100,
          600,
          1130,
          550,
          550,
          1100,
          1100,
          2500,
          2500,
          2500,
          600,
          1100,
          600,
          600,
          600,
          1100,
          600,
          1200,
          1200,
          900,
          1200,
          1600,
          1500,
          600,
          1100,
          1200,
          1200,
          1650,
          1650,
          1500,
          1100,
          600,
          1100,
          600,
          2000,
          2000,
          700,
          800,
          1500,
          2400,
          2400,
          1800,
          600,
          1100,
          1500,
          500,
          1500,
          600,
          900,
          1200,
          600,
          700,
          1100,
          500,
          1500,
          1500,
          600,
          1100,
          1500,
          1100,
          600,
          1500,
          1100,
          600,
          1600,
          700,
          1200,
          1500,
          1500,
          600,
          1300,
          600,
          600,
          600,
          600,
          1500,
          1500,
          1500,
          1000,
          1100,
          650,
          1700,
          3000,
          3000,
          1000,
          3000,
          1000,
          1350,
          1500,
          1400,
          600,
          750,
          1200,
          1940,
          1500,
          1350,
          1250,
          800,
          1450,
          1450,
          1150,
          1750,
          1750,
          1500,
          1500,
          600,
          1100,
          1500,
          1500,
          1400,
          1200,
          1500,
          1100,
          450,
          1200,
          1400,
          700,
          2400,
          1500,
          1100,
          900,
          900,
          1500,
          900,
          1800,
          1800,
          1600,
          1500,
          1500,
          1500,
          1500,
          1500,
          1200,
          1100,
          1200,
          2000,
          800,
          550,
          550,
          600,
          1000,
          950,
          950,
          950,
          600,
          1800,
          1800,
          750,
          550,
          550,
          550,
          1450,
          1350,
          1350,
          1100,
          1200,
          1100,
          1700,
          1200,
          1200,
          1350,
          2000,
          3000,
          3000,
          3000,
          1500,
          1500,
          1500,
          1500,
          1100,
          1100,
          1400,
          600,
          600,
          900,
          9000,
          800,
          8000,
          8000,
          8000,
          800,
          800,
          800,
          900,
          900,
          800,
          800,
          800,
          800,
          800,
          600,
          850,
          500,
          500,
          800,
          800,
          800,
          900,
          500,
          500,
          1200,
          1200,
          8000,
          800,
          800,
          800,
          800,
          800,
          800,
          950,
          600,
          600,
          1500,
          1500,
          1500,
          1500,
          600,
          500,
          500,
          1650,
          1650,
          750,
          600,
          600,
          1700,
          500,
          1400,
          1400,
          1400,
          1400,
          1400,
          1400,
          800,
          500,
          500,
          500,
          500,
          1500,
          500,
          1500,
          600,
          600,
          500,
          600,
          1400,
          1400,
          600,
          1350,
          600,
          600,
          600,
          750,
          1000,
          1000,
          750,
          1700,
          1700,
          600,
          750,
          750,
          750,
          750,
          1500,
          800,
          625,
          350,
          500,
          500,
          550,
          600,
          500,
          600,
          750,
          1700,
          1900,
          1700,
          7000,
          10000,
          1900,
          2000,
          2000,
          1900,
          1900,
          900,
          1700,
          1550,
          800,
          800,
          800,
          600,
          600,
          550,
          1000,
          550,
          600,
          600,
          550,
          500,
          750,
          550,
          550,
          500,
          500,
          1300,
          1300,
          600,
          1700,
          1700,
          600,
          600,
          600,
          800,
          800,
          1700,
          600,
          550,
          500,
          500,
          500,
          800,
          800,
          800,
          600,
          700,
          1200,
          800,
          800,
          800,
          800,
          700,
          1500,
          1500,
          1500,
          900,
          550,
          600,
          550,
          550,
          500,
          550,
          500,
          750,
          500,
          550,
          1350,
          1350,
          600,
          600,
          600,
          600,
          900,
          1700,
          600,
          250,
          500,
          600,
          500,
          500,
          550,
          1250,
          550,
          550,
          600,
          600,
          550,
          500,
          1250,
          1350,
          2500,
          1350,
          2500,
          1350,
          1350,
          400,
          600,
          500,
          600,
          600,
          600,
          600,
          550,
          600,
          600,
          1000,
          700,
          600,
          600,
          600,
          600,
          600,
          1450,
          1300,
          1600,
          1000,
          600,
          600,
          500,
          600,
          500,
          500,
          1350,
          600,
          1350,
          600,
          600,
          600,
          1350,
          1350,
          600,
          800,
          1500,
          600,
          800,
          600,
          750,
          900,
          600,
          1600,
          500,
          500,
          600,
          600,
          600,
          1700,
          1700,
          1200,
          600,
          550,
          550,
          550,
          550,
          500,
          500,
          600,
          600,
          600,
          1700,
          1700,
          500,
          6500,
          700,
          600,
          1800,
          800,
          800,
          800,
          600,
          6500,
          6500,
          558,
          506,
          10200,
          400,
          1550,
          500,
          450,
          400,
          400,
          400,
          600,
          1119,
          600,
          750,
          800,
          600,
          600,
          600,
          600,
          600,
          600,
          600,
          600,
          600,
          600,
          600,
          600,
          750,
          900,
          777,
          600,
          900,
          600,
          1800,
          1800,
          900,
          800,
          800,
          800,
          1250,
          1250,
          550,
          900,
          900,
          550,
          600,
          800,
          600,
          1700,
          600,
          600,
          600,
          600,
          800,
          2000,
          2000,
          1500,
          1500,
          1500,
          1600,
          1700,
          1700,
          1700,
          800,
          800,
          800,
          800,
          800,
          800,
          600,
          2000,
          1700,
          1700,
          1200,
          1000,
          1500,
          800,
          1500,
          1100,
          700,
          900,
          1500,
          1100,
          900,
          900,
          900,
          700,
          1100,
          700,
          1100,
          1500,
          1100,
          700,
          900,
          2000,
          2000,
          2000,
          600,
          600,
          1850,
          1850,
          1850,
          600,
          600,
          1750,
          600,
          600,
          1500,
          1600,
          600,
          500,
          600,
          900,
          1800,
          1400,
          1400,
          1600,
          1600,
          600,
          600,
          800,
          2500,
          800,
          600,
          600,
          800,
          800,
          600,
          800,
          600,
          800,
          800,
          800,
          800,
          800,
          2500,
          1200,
          800,
          1200,
          800,
          600,
          500,
          900,
          600,
          1700,
          600,
          600,
          800,
          600,
          900,
          1200,
          1200,
          2500,
          550,
          550,
          1200,
          600,
          1200,
          750,
          800,
          800,
          800,
          800,
          800,
          800,
          800,
          2500,
          600,
          600,
          600,
          600,
          1350,
          600,
          600,
          600,
          600,
          450,
          500,
          800,
          1800,
          1800,
          750,
          500,
          600,
          1330,
          800,
          1000,
          800,
          600,
          800,
          800,
          1000,
          6500,
          6500
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Rated Power (kW)"
          }
         },
         "colorscale": [
          [
           0,
           "#0d0887"
          ],
          [
           0.1111111111111111,
           "#46039f"
          ],
          [
           0.2222222222222222,
           "#7201a8"
          ],
          [
           0.3333333333333333,
           "#9c179e"
          ],
          [
           0.4444444444444444,
           "#bd3786"
          ],
          [
           0.5555555555555556,
           "#d8576b"
          ],
          [
           0.6666666666666666,
           "#ed7953"
          ],
          [
           0.7777777777777778,
           "#fb9f3a"
          ],
          [
           0.8888888888888888,
           "#fdca26"
          ],
          [
           1,
           "#f0f921"
          ]
         ]
        },
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Flow vs Pressure colored by Rated Power"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Flow (m3/h)"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Pressure (Pa)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "fig = px.scatter(df, x='Actual flow volume air/gas', y='Pressure, static', color='Rated power',\n",
    "                 title='Flow vs Pressure colored by Rated Power',\n",
    "                 labels={'Actual flow volume air/gas': 'Flow (m3/h)', 'Pressure, static': 'Pressure (Pa)', 'Rated power': 'Rated Power (kW)'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "\n",
    "if 'Fan Type' in df.columns:\n",
    "    fig = px.pie(df, values='Rated power', names='Fan Type', title='Distribution of Rated Power by Fan Type')\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"the values distribution based on Power Category\")\n",
    "\n",
    "df['Power Category'] = pd.cut(df['Rated power'], bins=[0, 10, 20, 30, 40, 50, 60, np.inf], labels=['0-10', '10-20', '20-30', '30-40', '40-50', '50-60', '60+'])\n",
    "\n",
    "fig = px.pie(df, values='Rated power', names='Power Category', title='Distribution of Rated Power by Category')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# load the data set\n",
    "df = pd.read_csv('/Users/nanthansnair/Downloads/jupiter/data1.csv')\n",
    "df['Actual flow volume air/gas'] = df['Actual flow volume air/gas'].str.replace(',', '').str.replace(' m3/h', '').astype(float)\n",
    "df['Pressure, static'] = df['Pressure, static'].str.replace(',', '').str.replace(' Pa', '').astype(float)\n",
    "df['Rated power'] = df['Rated power'].str.replace(' kW', '').astype(float)\n",
    "df.drop(columns=['Unnamed: 5'], inplace=True)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# to check if the columns are not empty\n",
    "if not df.empty:\n",
    "    X = df[['Actual flow volume air/gas', 'Pressure, static']]\n",
    "    y = df['Rated power']\n",
    "\n",
    "    print(\"Shape of X:\", X.shape)\n",
    "    print(\"Shape of y:\", y.shape)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    print(\"First 5 rows of X_scaled:\", X_scaled[:5])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_test shape:\", X_test.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "    # creating of neural network with 3 hidden layers\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=2, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    # model training with 200 epoches\n",
    "    model.fit(X_train, y_train, epochs=200, batch_size=5, verbose=1)\n",
    "\n",
    "    # working of the model and training\n",
    "    loss = model.evaluate(X_test, y_test)\n",
    "    print(f'Test Loss: {loss}')\n",
    "\n",
    "    # reccomend the correct fan\n",
    "    def recommend_fan(flow, pressure):\n",
    "        input_scaled = scaler.transform(np.array([[flow, pressure]]))\n",
    "        predicted_power = model.predict(input_scaled)[0][0]\n",
    "        df['Power Difference'] = abs(df['Rated power'] - predicted_power)\n",
    "        sorted_fans = df.sort_values(by='Power Difference', ascending=True)\n",
    "        best_fan = sorted_fans.iloc[0]\n",
    "        return best_fan\n",
    "\n",
    "\n",
    "    best_fan = recommend_fan(154000,1800)\n",
    "    print(best_fan)\n",
    "    \n",
    "else:\n",
    "    print(\"some error occurred while processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# use flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "# loading dataset\n",
    "df = pd.read_csv('/Users/nanthansnair/Downloads/jupiter/data1.csv')\n",
    "df['Actual flow volume air/gas'] = df['Actual flow volume air/gas'].str.replace(',', '').str.replace(' m3/h', '').astype(float)\n",
    "df['Pressure, static'] = df['Pressure, static'].str.replace(',', '').str.replace(' Pa', '').astype(float)\n",
    "df['Rated power'] = df['Rated power'].str.replace(' kW', '').astype(float)\n",
    "df.drop(columns=['Unnamed: 5'], inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df[['Actual flow volume air/gas', 'Pressure, static']]\n",
    "y = df['Rated power']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=2, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=5, verbose=1)\n",
    "\n",
    "# function\n",
    "def recommend_fan(flow, pressure):\n",
    "    input_scaled = scaler.transform(np.array([[flow, pressure]]))\n",
    "    predicted_power = model.predict(input_scaled)[0][0]\n",
    "    df['Power Difference'] = abs(df['Rated power'] - predicted_power)\n",
    "    sorted_fans = df.sort_values(by='Power Difference', ascending=True)\n",
    "    best_fan = sorted_fans.iloc[0]\n",
    "    return best_fan.to_dict()\n",
    "\n",
    "@app.route('/recommend_fan', methods=['POST'])\n",
    "def recommend_fan_endpoint():\n",
    "    data = request.get_json()\n",
    "    flow = data['flow']\n",
    "    pressure = data['pressure']\n",
    "    recommended_fan = recommend_fan(flow, pressure)\n",
    "    return jsonify(recommended_fan)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "df = pd.read_csv('/Users/nanthansnair/Downloads/jupiter/data1.csv')\n",
    "df['Actual flow volume air/gas'] = df['Actual flow volume air/gas'].str.replace(',', '').str.replace(' m3/h', '').astype(float)\n",
    "df['Pressure, static'] = df['Pressure, static'].str.replace(',', '').str.replace(' Pa', '').astype(float)\n",
    "df['Rated power'] = df['Rated power'].str.replace(' kW', '').astype(float)\n",
    "df.drop(columns=['Unnamed: 5'], inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df[['Actual flow volume air/gas', 'Pressure, static']]\n",
    "y = df['Rated power']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=2, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=5, verbose=1)\n",
    "\n",
    "def recommend_fan(flow, pressure):\n",
    "    input_scaled = scaler.transform(np.array([[flow, pressure]]))\n",
    "    predicted_power = model.predict(input_scaled)[0][0]\n",
    "    df['Power Difference'] = abs(df['Rated power'] - predicted_power)\n",
    "    sorted_fans = df.sort_values(by='Power Difference', ascending=True)\n",
    "    best_fan = sorted_fans.iloc[0]\n",
    "    return best_fan.to_dict()\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('display.html')\n",
    "\n",
    "@app.route('/recommend_fan', methods=['POST'])\n",
    "def recommend_fan_endpoint():\n",
    "    data = request.get_json()\n",
    "    flow = data['flow']\n",
    "    pressure = data['pressure']\n",
    "    recommended_fan = recommend_fan(flow, pressure)\n",
    "    return jsonify(recommended_fan)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "from flask_cors import CORS\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "\n",
    "df = pd.read_csv('/Users/nanthansnair/Downloads/jupiter/data1.csv')\n",
    "df['Actual flow volume air/gas'] = df['Actual flow volume air/gas'].str.replace(',', '').str.replace(' m3/h', '').astype(float)\n",
    "df['Pressure, static'] = df['Pressure, static'].str.replace(',', '').str.replace(' Pa', '').astype(float)\n",
    "df['Rated power'] = df['Rated power'].str.replace(' kW', '').astype(float)\n",
    "df.drop(columns=['Unnamed: 5'], inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df[['Actual flow volume air/gas', 'Pressure, static']]\n",
    "y = df['Rated power']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=2, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=5, verbose=1)\n",
    "\n",
    "def recommend_fan(flow, pressure):\n",
    "    input_scaled = scaler.transform(np.array([[flow, pressure]]))\n",
    "    predicted_power = model.predict(input_scaled)[0][0]\n",
    "    df['Power Difference'] = abs(df['Rated power'] - predicted_power)\n",
    "    sorted_fans = df.sort_values(by='Power Difference', ascending=True)\n",
    "    best_fan = sorted_fans.iloc[0]\n",
    "    return best_fan.to_dict()\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('display.html')\n",
    "\n",
    "@app.route('/recommend_fan', methods=['POST'])\n",
    "def recommend_fan_endpoint():\n",
    "    data = request.get_json()\n",
    "    flow = data['flow']\n",
    "    pressure = data['pressure']\n",
    "    recommended_fan = recommend_fan(flow, pressure)\n",
    "    return jsonify(recommended_fan)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# load the data set\n",
    "df = pd.read_csv('/Users/nanthansnair/Downloads/jupiter/data1.csv')\n",
    "df['Actual flow volume air/gas'] = df['Actual flow volume air/gas'].str.replace(',', '').str.replace(' m3/h', '').astype(float)\n",
    "df['Pressure, static'] = df['Pressure, static'].str.replace(',', '').str.replace(' Pa', '').astype(float)\n",
    "df['Rated power'] = df['Rated power'].str.replace(' kW', '').astype(float)\n",
    "df.drop(columns=['Unnamed: 5'], inplace=True)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# to check if the columns are not empty\n",
    "if not df.empty:\n",
    "    X = df[['Actual flow volume air/gas', 'Pressure, static']]\n",
    "    y = df['Rated power']\n",
    "\n",
    "    print(\"Shape of X:\", X.shape)\n",
    "    print(\"Shape of y:\", y.shape)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    print(\"First 5 rows of X_scaled:\", X_scaled[:5])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_test shape:\", X_test.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "    # creating of neural network with 3 hidden layers\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=2, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    # model training with 200 epoches\n",
    "    model.fit(X_train, y_train, epochs=200, batch_size=5, verbose=1)\n",
    "\n",
    "    # working of the model and training\n",
    "    loss = model.evaluate(X_test, y_test)\n",
    "    print(f'Test Loss: {loss}')\n",
    "\n",
    "    # reccomend the correct fan\n",
    "    def recommend_fan(flow, pressure):\n",
    "        input_scaled = scaler.transform(np.array([[flow, pressure]]))\n",
    "        predicted_power = model.predict(input_scaled)[0][0]\n",
    "        df['Power Difference'] = abs(df['Rated power'] - predicted_power)\n",
    "        sorted_fans = df.sort_values(by='Power Difference', ascending=True)\n",
    "        best_fan = sorted_fans.iloc[0]\n",
    "        return best_fan\n",
    "\n",
    "\n",
    "    best_fan = recommend_fan(27000,1330)\n",
    "    print(best_fan)\n",
    "    \n",
    "else:\n",
    "    print(\"some error occurred while processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# load the data set\n",
    "df = pd.read_csv('/Users/nanthansnair/Downloads/jupiter/data1.csv')\n",
    "df['Actual flow volume air/gas'] = df['Actual flow volume air/gas'].str.replace(',', '').str.replace(' m3/h', '').astype(float)\n",
    "df['Pressure, static'] = df['Pressure, static'].str.replace(',', '').str.replace(' Pa', '').astype(float)\n",
    "df['Rated power'] = df['Rated power'].str.replace(' kW', '').astype(float)\n",
    "df.drop(columns=['Unnamed: 5'], inplace=True)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# to check if the columns are not empty\n",
    "if not df.empty:\n",
    "    X = df[['Actual flow volume air/gas', 'Pressure, static']]\n",
    "    y = df['Rated power']\n",
    "\n",
    "    print(\"Shape of X:\", X.shape)\n",
    "    print(\"Shape of y:\", y.shape)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    print(\"First 5 rows of X_scaled:\", X_scaled[:5])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_test shape:\", X_test.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "    # creating of neural network with 3 hidden layers\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=2, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    # model training with 200 epoches\n",
    "    model.fit(X_train, y_train, epochs=200, batch_size=5, verbose=1)\n",
    "\n",
    "    # working of the model and training\n",
    "    loss = model.evaluate(X_test, y_test)\n",
    "    print(f'Test Loss: {loss}')\n",
    "\n",
    "    # reccomend the correct fan\n",
    "    def recommend_fan(flow, pressure):\n",
    "        input_scaled = scaler.transform(np.array([[flow, pressure]]))\n",
    "        predicted_power = model.predict(input_scaled)[0][0]\n",
    "        df['Power Difference'] = abs(df['Rated power'] - predicted_power)\n",
    "        sorted_fans = df.sort_values(by='Power Difference', ascending=True)\n",
    "        best_fan = sorted_fans.iloc[0]\n",
    "        return best_fan\n",
    "\n",
    "\n",
    "    best_fan = recommend_fan(174000,1700)\n",
    "    print(best_fan)\n",
    "    \n",
    "else:\n",
    "    print(\"some error occurred while processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# load the data set\n",
    "df = pd.read_csv('/Users/nanthansnair/Downloads/jupiter/data1.csv')\n",
    "df['Actual flow volume air/gas'] = df['Actual flow volume air/gas'].str.replace(',', '').str.replace(' m3/h', '').astype(float)\n",
    "df['Pressure, static'] = df['Pressure, static'].str.replace(',', '').str.replace(' Pa', '').astype(float)\n",
    "df['Rated power'] = df['Rated power'].str.replace(' kW', '').astype(float)\n",
    "df.drop(columns=['Unnamed: 5'], inplace=True)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# to check if the columns are not empty\n",
    "if not df.empty:\n",
    "    X = df[['Actual flow volume air/gas', 'Pressure, static']]\n",
    "    y = df['Rated power']\n",
    "\n",
    "    print(\"Shape of X:\", X.shape)\n",
    "    print(\"Shape of y:\", y.shape)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    print(\"First 5 rows of X_scaled:\", X_scaled[:5])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_test shape:\", X_test.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "    # creating of neural network with 3 hidden layers\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=2, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    # model training with 200 epoches\n",
    "    model.fit(X_train, y_train, epochs=200, batch_size=5, verbose=1)\n",
    "\n",
    "    # working of the model and training\n",
    "    loss = model.evaluate(X_test, y_test)\n",
    "    print(f'Test Loss: {loss}')\n",
    "\n",
    "    # reccomend the correct fan\n",
    "    def recommend_fan(flow, pressure):\n",
    "        input_scaled = scaler.transform(np.array([[flow, pressure]]))\n",
    "        predicted_power = model.predict(input_scaled)[0][0]\n",
    "        df['Power Difference'] = abs(df['Rated power'] - predicted_power)\n",
    "        sorted_fans = df.sort_values(by='Power Difference', ascending=True)\n",
    "        best_fan = sorted_fans.iloc[0]\n",
    "        return best_fan\n",
    "\n",
    "\n",
    "    best_fan = recommend_fan(15125,8000)\n",
    "    print(best_fan)\n",
    "    \n",
    "else:\n",
    "    print(\"some error occurred while processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - loss: 1745.4711\n",
      "Epoch 2/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 1182.2698\n",
      "Epoch 3/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step - loss: 202.3626\n",
      "Epoch 4/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269us/step - loss: 108.5529\n",
      "Epoch 5/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267us/step - loss: 90.0082\n",
      "Epoch 6/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step - loss: 79.2877\n",
      "Epoch 7/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289us/step - loss: 71.2252\n",
      "Epoch 8/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281us/step - loss: 63.8101\n",
      "Epoch 9/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 57.7053\n",
      "Epoch 10/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285us/step - loss: 52.4579\n",
      "Epoch 11/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268us/step - loss: 48.3823\n",
      "Epoch 12/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280us/step - loss: 44.9241\n",
      "Epoch 13/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270us/step - loss: 41.9338\n",
      "Epoch 14/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279us/step - loss: 39.1831\n",
      "Epoch 15/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287us/step - loss: 37.0013\n",
      "Epoch 16/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279us/step - loss: 34.6358\n",
      "Epoch 17/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271us/step - loss: 32.6510\n",
      "Epoch 18/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - loss: 30.8588\n",
      "Epoch 19/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267us/step - loss: 29.6076\n",
      "Epoch 20/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270us/step - loss: 28.1583\n",
      "Epoch 21/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276us/step - loss: 26.9727\n",
      "Epoch 22/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269us/step - loss: 25.9167\n",
      "Epoch 23/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step - loss: 25.0372\n",
      "Epoch 24/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266us/step - loss: 24.0933\n",
      "Epoch 25/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271us/step - loss: 23.6248\n",
      "Epoch 26/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265us/step - loss: 22.9022\n",
      "Epoch 27/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 22.2664\n",
      "Epoch 28/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 21.6905\n",
      "Epoch 29/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step - loss: 21.2401\n",
      "Epoch 30/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 20.7574\n",
      "Epoch 31/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 20.3768\n",
      "Epoch 32/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - loss: 20.0265\n",
      "Epoch 33/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271us/step - loss: 19.7219\n",
      "Epoch 34/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277us/step - loss: 19.4808\n",
      "Epoch 35/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280us/step - loss: 19.2380\n",
      "Epoch 36/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269us/step - loss: 19.0414\n",
      "Epoch 37/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284us/step - loss: 18.7840\n",
      "Epoch 38/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286us/step - loss: 18.6049\n",
      "Epoch 39/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271us/step - loss: 18.5116\n",
      "Epoch 40/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 18.3331\n",
      "Epoch 41/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 18.2717\n",
      "Epoch 42/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265us/step - loss: 18.1815\n",
      "Epoch 43/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step - loss: 17.9902\n",
      "Epoch 44/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263us/step - loss: 17.9468\n",
      "Epoch 45/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263us/step - loss: 17.8627\n",
      "Epoch 46/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step - loss: 17.7839\n",
      "Epoch 47/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266us/step - loss: 17.6671\n",
      "Epoch 48/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263us/step - loss: 17.5868\n",
      "Epoch 49/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263us/step - loss: 17.5024\n",
      "Epoch 50/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - loss: 17.4534\n",
      "Epoch 51/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 17.3543\n",
      "Epoch 52/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252us/step - loss: 17.3419\n",
      "Epoch 53/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252us/step - loss: 17.2287\n",
      "Epoch 54/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251us/step - loss: 17.4656\n",
      "Epoch 55/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249us/step - loss: 17.1894\n",
      "Epoch 56/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251us/step - loss: 16.9530\n",
      "Epoch 57/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 16.9797\n",
      "Epoch 58/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253us/step - loss: 16.7709\n",
      "Epoch 59/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253us/step - loss: 16.6423\n",
      "Epoch 60/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 16.6586\n",
      "Epoch 61/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step - loss: 16.4913\n",
      "Epoch 62/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272us/step - loss: 16.3824\n",
      "Epoch 63/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266us/step - loss: 16.3382\n",
      "Epoch 64/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step - loss: 16.2083\n",
      "Epoch 65/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271us/step - loss: 16.1565\n",
      "Epoch 66/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267us/step - loss: 16.0215\n",
      "Epoch 67/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267us/step - loss: 15.9297\n",
      "Epoch 68/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step - loss: 15.8579\n",
      "Epoch 69/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 15.7338\n",
      "Epoch 70/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252us/step - loss: 15.7009\n",
      "Epoch 71/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step - loss: 15.7835\n",
      "Epoch 72/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251us/step - loss: 15.6883\n",
      "Epoch 73/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - loss: 15.5308\n",
      "Epoch 74/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 15.4758\n",
      "Epoch 75/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252us/step - loss: 15.4355\n",
      "Epoch 76/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252us/step - loss: 15.2917\n",
      "Epoch 77/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250us/step - loss: 15.2634\n",
      "Epoch 78/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253us/step - loss: 15.1723\n",
      "Epoch 79/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252us/step - loss: 15.1196\n",
      "Epoch 80/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249us/step - loss: 14.9801\n",
      "Epoch 81/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251us/step - loss: 15.0350\n",
      "Epoch 82/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253us/step - loss: 14.8617\n",
      "Epoch 83/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248us/step - loss: 14.7831\n",
      "Epoch 84/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250us/step - loss: 14.7413\n",
      "Epoch 85/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 14.6309\n",
      "Epoch 86/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step - loss: 14.6390\n",
      "Epoch 87/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step - loss: 14.6048\n",
      "Epoch 88/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 14.4991\n",
      "Epoch 89/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step - loss: 14.5142\n",
      "Epoch 90/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step - loss: 14.4164\n",
      "Epoch 91/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step - loss: 14.3659\n",
      "Epoch 92/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252us/step - loss: 14.3368\n",
      "Epoch 93/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 14.2938\n",
      "Epoch 94/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273us/step - loss: 14.2333\n",
      "Epoch 95/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - loss: 14.2336\n",
      "Epoch 96/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step - loss: 14.1640\n",
      "Epoch 97/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 14.1037\n",
      "Epoch 98/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265us/step - loss: 14.0720\n",
      "Epoch 99/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 14.0627\n",
      "Epoch 100/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277us/step - loss: 14.0424\n",
      "Epoch 101/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263us/step - loss: 13.9946\n",
      "Epoch 102/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269us/step - loss: 13.8788\n",
      "Epoch 103/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 13.9090\n",
      "Epoch 104/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265us/step - loss: 13.9167\n",
      "Epoch 105/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270us/step - loss: 13.7864\n",
      "Epoch 106/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268us/step - loss: 13.8141\n",
      "Epoch 107/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step - loss: 13.8261\n",
      "Epoch 108/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275us/step - loss: 13.7744\n",
      "Epoch 109/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 13.7481\n",
      "Epoch 110/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265us/step - loss: 13.7323\n",
      "Epoch 111/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 13.7114\n",
      "Epoch 112/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - loss: 13.6495\n",
      "Epoch 113/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276us/step - loss: 13.6664\n",
      "Epoch 114/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275us/step - loss: 13.6546\n",
      "Epoch 115/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282us/step - loss: 13.5910\n",
      "Epoch 116/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284us/step - loss: 13.5997\n",
      "Epoch 117/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268us/step - loss: 13.5615\n",
      "Epoch 118/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274us/step - loss: 13.5852\n",
      "Epoch 119/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267us/step - loss: 13.5263\n",
      "Epoch 120/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271us/step - loss: 13.4622\n",
      "Epoch 121/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step - loss: 13.4880\n",
      "Epoch 122/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step - loss: 13.4767\n",
      "Epoch 123/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step - loss: 13.3880\n",
      "Epoch 124/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267us/step - loss: 13.4043\n",
      "Epoch 125/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271us/step - loss: 13.3038\n",
      "Epoch 126/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step - loss: 13.3635\n",
      "Epoch 127/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269us/step - loss: 13.3306\n",
      "Epoch 128/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 13.2479\n",
      "Epoch 129/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - loss: 13.3306\n",
      "Epoch 130/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - loss: 13.2465\n",
      "Epoch 131/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265us/step - loss: 13.3423\n",
      "Epoch 132/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step - loss: 13.2578\n",
      "Epoch 133/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 13.2844\n",
      "Epoch 134/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 13.2177\n",
      "Epoch 135/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 13.2353\n",
      "Epoch 136/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263us/step - loss: 13.2503\n",
      "Epoch 137/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287us/step - loss: 13.2781\n",
      "Epoch 138/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 13.2046\n",
      "Epoch 139/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 13.2345\n",
      "Epoch 140/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263us/step - loss: 13.2186\n",
      "Epoch 141/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 13.1894\n",
      "Epoch 142/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 13.2064\n",
      "Epoch 143/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step - loss: 13.2402\n",
      "Epoch 144/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 13.2024\n",
      "Epoch 145/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 13.1790\n",
      "Epoch 146/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step - loss: 13.2138\n",
      "Epoch 147/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265us/step - loss: 13.1628\n",
      "Epoch 148/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - loss: 13.1720\n",
      "Epoch 149/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270us/step - loss: 13.1858\n",
      "Epoch 150/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step - loss: 13.1210\n",
      "Epoch 151/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252us/step - loss: 13.1898\n",
      "Epoch 152/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 13.1590\n",
      "Epoch 153/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 13.1452\n",
      "Epoch 154/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 13.0960\n",
      "Epoch 155/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 13.0802\n",
      "Epoch 156/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 12.9906\n",
      "Epoch 157/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step - loss: 13.0495\n",
      "Epoch 158/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251us/step - loss: 13.0273\n",
      "Epoch 159/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 13.0065\n",
      "Epoch 160/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 13.0045\n",
      "Epoch 161/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 13.0647\n",
      "Epoch 162/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step - loss: 13.0399\n",
      "Epoch 163/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step - loss: 12.9553\n",
      "Epoch 164/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 12.9512\n",
      "Epoch 165/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 12.9728\n",
      "Epoch 166/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - loss: 12.9161\n",
      "Epoch 167/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273us/step - loss: 12.9100\n",
      "Epoch 168/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step - loss: 12.9457\n",
      "Epoch 169/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 12.8899\n",
      "Epoch 170/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 12.8856\n",
      "Epoch 171/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step - loss: 12.9095\n",
      "Epoch 172/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 12.8866\n",
      "Epoch 173/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 12.8901\n",
      "Epoch 174/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 12.8625\n",
      "Epoch 175/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 12.8304\n",
      "Epoch 176/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 12.8327\n",
      "Epoch 177/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253us/step - loss: 12.8344\n",
      "Epoch 178/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 12.8231\n",
      "Epoch 179/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step - loss: 12.7838\n",
      "Epoch 180/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 12.7817\n",
      "Epoch 181/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 12.7010\n",
      "Epoch 182/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 12.7524\n",
      "Epoch 183/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 12.7465\n",
      "Epoch 184/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - loss: 12.7718\n",
      "Epoch 185/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step - loss: 12.7439\n",
      "Epoch 186/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267us/step - loss: 12.7310\n",
      "Epoch 187/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 12.7011\n",
      "Epoch 188/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 12.7616\n",
      "Epoch 189/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251us/step - loss: 12.6963\n",
      "Epoch 190/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 12.6612\n",
      "Epoch 191/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 12.6921\n",
      "Epoch 192/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 12.6718\n",
      "Epoch 193/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265us/step - loss: 12.6510\n",
      "Epoch 194/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 12.7124\n",
      "Epoch 195/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 12.6781\n",
      "Epoch 196/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 12.6558\n",
      "Epoch 197/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 12.6406\n",
      "Epoch 198/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step - loss: 12.6214\n",
      "Epoch 199/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 12.6205\n",
      "Epoch 200/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 12.6332\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5001\n",
      " * Running on http://172.20.10.2:5001\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [30/May/2024 15:57:44] \"OPTIONS /recommend_fan HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "127.0.0.1 - - [30/May/2024 15:57:44] \"POST /recommend_fan HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/May/2024 15:58:31] \"OPTIONS /recommend_fan HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "127.0.0.1 - - [30/May/2024 15:58:31] \"POST /recommend_fan HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/May/2024 15:59:00] \"OPTIONS /recommend_fan HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "127.0.0.1 - - [30/May/2024 15:59:00] \"POST /recommend_fan HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/May/2024 16:00:35] \"OPTIONS /recommend_fan HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "127.0.0.1 - - [30/May/2024 16:00:35] \"POST /recommend_fan HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/May/2024 16:00:59] \"OPTIONS /recommend_fan HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "127.0.0.1 - - [30/May/2024 16:00:59] \"POST /recommend_fan HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "from flask_cors import CORS\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "\n",
    "df = pd.read_csv('/Users/nanthansnair/Downloads/jupiter/data1.csv')\n",
    "df['Actual flow volume air/gas'] = df['Actual flow volume air/gas'].str.replace(',', '').str.replace(' m3/h', '').astype(float)\n",
    "df['Pressure, static'] = df['Pressure, static'].str.replace(',', '').str.replace(' Pa', '').astype(float)\n",
    "df['Rated power'] = df['Rated power'].str.replace(' kW', '').astype(float)\n",
    "df.drop(columns=['Unnamed: 5'], inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df[['Actual flow volume air/gas', 'Pressure, static']]\n",
    "y = df['Rated power']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=2, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=5, verbose=1)\n",
    "\n",
    "def recommend_fan(flow, pressure):\n",
    "    input_scaled = scaler.transform(np.array([[flow, pressure]]))\n",
    "    predicted_power = model.predict(input_scaled)[0][0]\n",
    "    df['Power Difference'] = abs(df['Rated power'] - predicted_power)\n",
    "    sorted_fans = df.sort_values(by='Power Difference', ascending=True)\n",
    "    best_fan = sorted_fans.iloc[0]\n",
    "    return best_fan.to_dict()\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('temp.html')\n",
    "\n",
    "@app.route('/recommend_fan', methods=['POST'])\n",
    "def recommend_fan_endpoint():\n",
    "    data = request.get_json()\n",
    "    flow = data['flow']\n",
    "    pressure = data['pressure']\n",
    "    recommended_fan = recommend_fan(flow, pressure)\n",
    "    return jsonify(recommended_fan)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - loss: 1752.8427\n",
      "Epoch 2/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274us/step - loss: 1176.0161\n",
      "Epoch 3/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268us/step - loss: 188.6523\n",
      "Epoch 4/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step - loss: 109.4292\n",
      "Epoch 5/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step - loss: 91.1948\n",
      "Epoch 6/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 81.1548\n",
      "Epoch 7/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 71.8958\n",
      "Epoch 8/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253us/step - loss: 63.2310\n",
      "Epoch 9/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 55.5545\n",
      "Epoch 10/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 49.4421\n",
      "Epoch 11/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - loss: 44.2577\n",
      "Epoch 12/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265us/step - loss: 40.0544\n",
      "Epoch 13/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 36.7770\n",
      "Epoch 14/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263us/step - loss: 34.1255\n",
      "Epoch 15/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step - loss: 31.9921\n",
      "Epoch 16/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step - loss: 30.0861\n",
      "Epoch 17/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step - loss: 28.5930\n",
      "Epoch 18/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274us/step - loss: 27.1783\n",
      "Epoch 19/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275us/step - loss: 26.0512\n",
      "Epoch 20/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270us/step - loss: 25.0773\n",
      "Epoch 21/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269us/step - loss: 24.1739\n",
      "Epoch 22/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272us/step - loss: 23.4749\n",
      "Epoch 23/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283us/step - loss: 22.8249\n",
      "Epoch 24/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step - loss: 22.2822\n",
      "Epoch 25/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step - loss: 21.7664\n",
      "Epoch 26/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265us/step - loss: 21.3583\n",
      "Epoch 27/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269us/step - loss: 20.9716\n",
      "Epoch 28/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - loss: 20.8817\n",
      "Epoch 29/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266us/step - loss: 20.3927\n",
      "Epoch 30/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267us/step - loss: 20.2738\n",
      "Epoch 31/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272us/step - loss: 19.9021\n",
      "Epoch 32/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267us/step - loss: 19.8149\n",
      "Epoch 33/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272us/step - loss: 19.4672\n",
      "Epoch 34/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271us/step - loss: 19.4592\n",
      "Epoch 35/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 19.1315\n",
      "Epoch 36/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276us/step - loss: 19.2218\n",
      "Epoch 37/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271us/step - loss: 18.9590\n",
      "Epoch 38/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266us/step - loss: 18.7964\n",
      "Epoch 39/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276us/step - loss: 18.7012\n",
      "Epoch 40/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268us/step - loss: 18.6256\n",
      "Epoch 41/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step - loss: 18.4765\n",
      "Epoch 42/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263us/step - loss: 18.3342\n",
      "Epoch 43/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step - loss: 18.1811\n",
      "Epoch 44/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269us/step - loss: 18.0548\n",
      "Epoch 45/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273us/step - loss: 17.9476\n",
      "Epoch 46/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269us/step - loss: 17.7151\n",
      "Epoch 47/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271us/step - loss: 17.8432\n",
      "Epoch 48/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274us/step - loss: 17.7281\n",
      "Epoch 49/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - loss: 17.5590\n",
      "Epoch 50/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step - loss: 17.4667\n",
      "Epoch 51/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275us/step - loss: 17.2725\n",
      "Epoch 52/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270us/step - loss: 17.3591\n",
      "Epoch 53/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268us/step - loss: 17.2017\n",
      "Epoch 54/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step - loss: 17.0831\n",
      "Epoch 55/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266us/step - loss: 17.0832\n",
      "Epoch 56/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268us/step - loss: 17.0185\n",
      "Epoch 57/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step - loss: 16.9259\n",
      "Epoch 58/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step - loss: 16.8683\n",
      "Epoch 59/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - loss: 16.7778\n",
      "Epoch 60/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268us/step - loss: 16.6994\n",
      "Epoch 61/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265us/step - loss: 16.6361\n",
      "Epoch 62/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278us/step - loss: 16.5688\n",
      "Epoch 63/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271us/step - loss: 16.4949\n",
      "Epoch 64/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270us/step - loss: 16.4328\n",
      "Epoch 65/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 16.3788\n",
      "Epoch 66/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267us/step - loss: 16.3076\n",
      "Epoch 67/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286us/step - loss: 16.2355\n",
      "Epoch 68/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272us/step - loss: 16.1807\n",
      "Epoch 69/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step - loss: 16.2688\n",
      "Epoch 70/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step - loss: 16.2039\n",
      "Epoch 71/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 16.1418\n",
      "Epoch 72/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step - loss: 16.0532\n",
      "Epoch 73/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 16.0150\n",
      "Epoch 74/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 15.9472\n",
      "Epoch 75/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 15.8727\n",
      "Epoch 76/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 15.8095\n",
      "Epoch 77/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - loss: 15.7665\n",
      "Epoch 78/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270us/step - loss: 15.6798\n",
      "Epoch 79/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263us/step - loss: 15.6447\n",
      "Epoch 80/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 15.5837\n",
      "Epoch 81/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270us/step - loss: 15.5806\n",
      "Epoch 82/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268us/step - loss: 15.5541\n",
      "Epoch 83/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275us/step - loss: 15.4838\n",
      "Epoch 84/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268us/step - loss: 15.4080\n",
      "Epoch 85/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268us/step - loss: 15.3624\n",
      "Epoch 86/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266us/step - loss: 15.2869\n",
      "Epoch 87/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275us/step - loss: 15.2498\n",
      "Epoch 88/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270us/step - loss: 15.2025\n",
      "Epoch 89/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 15.1824\n",
      "Epoch 90/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step - loss: 15.1022\n",
      "Epoch 91/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265us/step - loss: 15.0580\n",
      "Epoch 92/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step - loss: 15.0127\n",
      "Epoch 93/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step - loss: 15.0071\n",
      "Epoch 94/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 14.9331\n",
      "Epoch 95/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step - loss: 14.9052\n",
      "Epoch 96/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252us/step - loss: 14.8605\n",
      "Epoch 97/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 14.8217\n",
      "Epoch 98/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 14.7723\n",
      "Epoch 99/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 14.7393\n",
      "Epoch 100/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step - loss: 14.7158\n",
      "Epoch 101/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step - loss: 14.6772\n",
      "Epoch 102/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - loss: 14.6415\n",
      "Epoch 103/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279us/step - loss: 14.6369\n",
      "Epoch 104/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 14.5923\n",
      "Epoch 105/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 14.5552\n",
      "Epoch 106/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 14.5059\n",
      "Epoch 107/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 14.5486\n",
      "Epoch 108/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 14.4302\n",
      "Epoch 109/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251us/step - loss: 14.4003\n",
      "Epoch 110/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step - loss: 14.4063\n",
      "Epoch 111/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 14.3669\n",
      "Epoch 112/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 14.2694\n",
      "Epoch 113/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 14.2852\n",
      "Epoch 114/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 14.2565\n",
      "Epoch 115/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 14.2101\n",
      "Epoch 116/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step - loss: 14.1561\n",
      "Epoch 117/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 14.1821\n",
      "Epoch 118/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 14.0990\n",
      "Epoch 119/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 14.1016\n",
      "Epoch 120/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 14.0523\n",
      "Epoch 121/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252us/step - loss: 14.0025\n",
      "Epoch 122/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253us/step - loss: 13.9655\n",
      "Epoch 123/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - loss: 13.9994\n",
      "Epoch 124/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step - loss: 13.9023\n",
      "Epoch 125/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 13.9094\n",
      "Epoch 126/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252us/step - loss: 13.9295\n",
      "Epoch 127/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 13.7678\n",
      "Epoch 128/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 13.8585\n",
      "Epoch 129/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step - loss: 13.7896\n",
      "Epoch 130/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281us/step - loss: 13.7393\n",
      "Epoch 131/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 13.7092\n",
      "Epoch 132/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 13.6844\n",
      "Epoch 133/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 13.6602\n",
      "Epoch 134/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 13.6095\n",
      "Epoch 135/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 13.6060\n",
      "Epoch 136/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 13.4989\n",
      "Epoch 137/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 13.5282\n",
      "Epoch 138/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 13.5123\n",
      "Epoch 139/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 13.4633\n",
      "Epoch 140/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step - loss: 13.4691\n",
      "Epoch 141/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step - loss: 13.4241\n",
      "Epoch 142/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 13.4022\n",
      "Epoch 143/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 13.3625\n",
      "Epoch 144/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - loss: 13.3660\n",
      "Epoch 145/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268us/step - loss: 13.3674\n",
      "Epoch 146/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step - loss: 13.3186\n",
      "Epoch 147/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 13.3124\n",
      "Epoch 148/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253us/step - loss: 13.2509\n",
      "Epoch 149/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step - loss: 13.2928\n",
      "Epoch 150/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 13.2293\n",
      "Epoch 151/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253us/step - loss: 13.2358\n",
      "Epoch 152/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 13.1777\n",
      "Epoch 153/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 13.1680\n",
      "Epoch 154/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 13.1202\n",
      "Epoch 155/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step - loss: 13.0893\n",
      "Epoch 156/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 13.0997\n",
      "Epoch 157/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 13.0618\n",
      "Epoch 158/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 13.0742\n",
      "Epoch 159/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step - loss: 13.0385\n",
      "Epoch 160/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 13.0300\n",
      "Epoch 161/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 12.9653\n",
      "Epoch 162/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282us/step - loss: 12.9595\n",
      "Epoch 163/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 12.9176\n",
      "Epoch 164/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285us/step - loss: 12.9112\n",
      "Epoch 165/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277us/step - loss: 12.8630\n",
      "Epoch 166/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274us/step - loss: 12.8896\n",
      "Epoch 167/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290us/step - loss: 12.8712\n",
      "Epoch 168/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - loss: 12.8786\n",
      "Epoch 169/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 12.8487\n",
      "Epoch 170/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 12.8292\n",
      "Epoch 171/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 12.7893\n",
      "Epoch 172/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263us/step - loss: 12.7940\n",
      "Epoch 173/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step - loss: 12.7841\n",
      "Epoch 174/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 12.8129\n",
      "Epoch 175/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 12.7868\n",
      "Epoch 176/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 12.7677\n",
      "Epoch 177/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step - loss: 12.7302\n",
      "Epoch 178/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step - loss: 12.7270\n",
      "Epoch 179/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step - loss: 12.7112\n",
      "Epoch 180/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 12.6886\n",
      "Epoch 181/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 12.6944\n",
      "Epoch 182/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263us/step - loss: 12.6584\n",
      "Epoch 183/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step - loss: 12.6579\n",
      "Epoch 184/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 12.6566\n",
      "Epoch 185/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step - loss: 12.6138\n",
      "Epoch 186/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 12.6275\n",
      "Epoch 187/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 12.6079\n",
      "Epoch 188/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step - loss: 12.6030\n",
      "Epoch 189/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267us/step - loss: 12.6082\n",
      "Epoch 190/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263us/step - loss: 12.5880\n",
      "Epoch 191/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - loss: 12.5480\n",
      "Epoch 192/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step - loss: 12.5502\n",
      "Epoch 193/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step - loss: 12.5412\n",
      "Epoch 194/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263us/step - loss: 12.5262\n",
      "Epoch 195/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265us/step - loss: 12.5379\n",
      "Epoch 196/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 12.5393\n",
      "Epoch 197/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - loss: 12.5125\n",
      "Epoch 198/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - loss: 12.5184\n",
      "Epoch 199/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step - loss: 12.5450\n",
      "Epoch 200/200\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269us/step - loss: 12.5020\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5001\n",
      " * Running on http://172.20.10.2:5001\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [30/May/2024 16:02:10] \"OPTIONS /recommend_fan HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "127.0.0.1 - - [30/May/2024 16:02:10] \"POST /recommend_fan HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/May/2024 16:03:01] \"OPTIONS /recommend_fan HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "127.0.0.1 - - [30/May/2024 16:03:01] \"POST /recommend_fan HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "from flask_cors import CORS\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "df = pd.read_csv('/Users/nanthansnair/Downloads/jupiter/data1.csv')\n",
    "df['Actual flow volume air/gas'] = df['Actual flow volume air/gas'].str.replace(',', '').str.replace(' m3/h', '').astype(float)\n",
    "df['Pressure, static'] = df['Pressure, static'].str.replace(',', '').str.replace(' Pa', '').astype(float)\n",
    "df['Rated power'] = df['Rated power'].str.replace(' kW', '').astype(float)\n",
    "df.drop(columns=['Unnamed: 5'], inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df[['Actual flow volume air/gas', 'Pressure, static']]\n",
    "y = df['Rated power']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=2, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=5, verbose=1)\n",
    "\n",
    "def recommend_fan(flow, pressure):\n",
    "    input_scaled = scaler.transform(np.array([[flow, pressure]]))\n",
    "    predicted_power = model.predict(input_scaled)[0][0]\n",
    "    df['Power Difference'] = abs(df['Rated power'] - predicted_power)\n",
    "    sorted_fans = df.sort_values(by='Power Difference', ascending=True)\n",
    "    best_fan = sorted_fans.iloc[0]\n",
    "    return best_fan.to_dict()\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('disp.html')\n",
    "\n",
    "@app.route('/recommend_fan', methods=['POST'])\n",
    "def recommend_fan_endpoint():\n",
    "    data = request.get_json()\n",
    "    flow = data['flow']\n",
    "    pressure = data['pressure']\n",
    "    recommended_fan = recommend_fan(flow, pressure)\n",
    "    return jsonify(recommended_fan)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "from flask_cors import CORS\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "df = pd.read_csv('/Users/nanthansnair/Downloads/jupiter/data1.csv')\n",
    "df['Actual flow volume air/gas'] = df['Actual flow volume air/gas'].str.replace(',', '').str.replace(' m3/h', '').astype(float)\n",
    "df['Pressure, static'] = df['Pressure, static'].str.replace(',', '').str.replace(' Pa', '').astype(float)\n",
    "df['Rated power'] = df['Rated power'].str.replace(' kW', '').astype(float)\n",
    "df.drop(columns=['Unnamed: 5'], inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df[['Actual flow volume air/gas', 'Pressure, static']]\n",
    "y = df['Rated power']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=2, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=5, verbose=1)\n",
    "\n",
    "def recommend_fan(flow, pressure):\n",
    "    try:\n",
    "        input_scaled = scaler.transform(np.array([[flow, pressure]]))\n",
    "        predicted_power = model.predict(input_scaled)[0][0]\n",
    "        df['Power Difference'] = abs(df['Rated power'] - predicted_power)\n",
    "        sorted_fans = df.sort_values(by='Power Difference', ascending=True)\n",
    "        best_fan = sorted_fans.iloc[0]\n",
    "        return best_fan.to_dict()\n",
    "    except Exception as e:\n",
    "        return {'error': str(e)}\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('values.html')\n",
    "\n",
    "@app.route('/recommend_fan', methods=['POST'])\n",
    "def recommend_fan_endpoint():\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        flow = data['flow']\n",
    "        pressure = data['pressure']\n",
    "        recommended_fan = recommend_fan(flow, pressure)\n",
    "        return jsonify(recommended_fan)\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5001)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
